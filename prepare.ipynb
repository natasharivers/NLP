{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "    - Lowercase everything\n",
    "    - Normalize unicode characters\n",
    "    - Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "<br>\n",
    "\n",
    "3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "<br>\n",
    "\n",
    "4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "<br>\n",
    "\n",
    "5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    - This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "<br>\n",
    "\n",
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "<br>\n",
    "\n",
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "<br>\n",
    "\n",
    "8. For each dataframe, produce the following columns:\n",
    "\n",
    "    - title to hold the title\n",
    "    - original to hold the original article/post content\n",
    "    - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "    - stemmed to hold the stemmed version of the cleaned data.\n",
    "    - lemmatized to hold the lemmatized version of the cleaned data.\n",
    "<br>\n",
    "\n",
    "9. Ask yourself:\n",
    "\n",
    "    - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the categories desired\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\"]\n",
    "\n",
    "#use function from acquire.py\n",
    "news_df = acquire.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Govt may lower import duty on EVs if Tesla man...</td>\n",
       "      <td>The government is open to consider reducing im...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Musk criticises Apple's 'walled garden', cobal...   \n",
       "3  Speculation around our plans for crypto not tr...   \n",
       "4  Govt may lower import duty on EVs if Tesla man...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "3  Amazon on Monday denied speculations that it w...  business  \n",
       "4  The government is open to consider reducing im...  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries has said in a statement that over 98% of its workers have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees, of March 31. Besides Reliance, Hindustan Unilever has also given at least one shot to 90% of employees, while Infosys inoculated 59% employees and TCS 70%.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use first article [0] to use as test string\n",
    "test_string = news_df.content[0]\n",
    "test_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1. Define a function named basic_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in the original text.\n",
    "    The text is all lowercased, \n",
    "    the text is encoded in ascii and any characters that are not ascii are ignored.\n",
    "    The text is then decoded in utf-8 and any characters that are not ascii are ignored\n",
    "    Additionally, special characters are all removed.\n",
    "    A clean article is then returned\n",
    "    '''\n",
    "    #lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    #normalize\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    #remove special characters and replaces it with blank\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reliance industries has said in a statement that over 98 of its workers have received at least one dose of covid19 vaccine so far the billionaire mukesh ambaniled conglomerate had over 236 lakh employees of march 31 besides reliance hindustan unilever has also given at least one shot to 90 of employees while infosys inoculated 59 employees and tcs 70'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "basic_clean(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. Define a function named tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string\n",
    "    and returns the string as individual tokens put back into the string\n",
    "    '''\n",
    "    #create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    #use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries has said in a statement that over 98 % of its workers have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees , of March 31. Besides Reliance , Hindustan Unilever has also given at least one shot to 90 % of employees , while Infosys inoculated 59 % employees and TCS 70 % .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "tokenize(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3. Define a function named stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    '''\n",
    "    This function takes in text\n",
    "    and returns the stem word joined back into the text\n",
    "    '''\n",
    "    #create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    #use the stem, split string using each word\n",
    "    stems = [ps.stem(word) for word in text.split()]\n",
    "    \n",
    "    #join stem word to string\n",
    "    text_stemmed = ' '.join(stems)\n",
    "\n",
    "    return text_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relianc industri ha said in a statement that over 98% of it worker have receiv at least one dose of covid-19 vaccin so far. the billionair mukesh ambani-l conglomer had over 2.36 lakh employees, of march 31. besid reliance, hindustan unilev ha also given at least one shot to 90% of employees, while infosi inocul 59% employe and tc 70%.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works, only root words (no past tense)\n",
    "stem(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4. Define a function named lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    '''\n",
    "    This function takes in text\n",
    "    and returns the lemmatized word joined back into the text\n",
    "    '''\n",
    "    #create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    #look at the article \n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    \n",
    "    #join lemmatized words into article\n",
    "    text_lemmatized= ' '.join(lemmas)\n",
    "\n",
    "    return text_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries ha said in a statement that over 98% of it worker have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees, of March 31. Besides Reliance, Hindustan Unilever ha also given at least one shot to 90% of employees, while Infosys inoculated 59% employee and TCS 70%.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "lemmatize(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5. Define a function named remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in text, extra words and exclude words\n",
    "    and returns a list of text with stopword removed\n",
    "    '''\n",
    "    #create stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    #remove excluded words from list\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    #add the extra words to the list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    #split the string into different words\n",
    "    words = string.split()\n",
    "    \n",
    "    #create a list of words that are not in the list\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    #join the words that are not stopwords (filtered words) back into the string\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries said statement 98% workers received least one dose COVID-19 vaccine far. The billionaire Mukesh Ambani-led conglomerate 2.36 lakh employees, March 31. Besides Reliance, Hindustan Unilever also given least one shot 90% employees, Infosys inoculated 59% employees TCS 70%.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Speculation around our plans for crypto not tr...   \n",
       "3  Musk criticises Apple's 'walled garden', cobal...   \n",
       "4  Factually incorrect: INOX on report of Amazon ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Amazon on Monday denied speculations that it w...  business  \n",
       "3  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "4  INOX Leisure denied a report that claimed Amaz...  business  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at news_ddf\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     reliance industry ha said statement 98 worker ...\n",
       "1     tesla ceo world ' secondrichest person elon mu...\n",
       "2     amazon monday denied speculation wa looking ac...\n",
       "3     tesla ' billionaire ceo elon musk criticised a...\n",
       "4     inox leisure denied report claimed amazon indi...\n",
       "                            ...                        \n",
       "93    marathi actor umesh kamat ha issued statement ...\n",
       "94    veteran actress savita bajaj unwell facing fin...\n",
       "95    shefali shah speaking international emmy award...\n",
       "96    taking instagram story singer aditya narayan d...\n",
       "97    actor adil hussain feel bollywood rope actor n...\n",
       "Name: content, Length: 98, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the content column to prep\n",
    "news_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     reliance industry vaccinates 98 worker hul ino...\n",
       "1       likely future earnings call tesla ceo elon musk\n",
       "2     musk criticises apple ' ' walled garden ' coba...\n",
       "3     speculation around plan crypto true amazon bit...\n",
       "4     govt may lower import duty ev tesla manufactur...\n",
       "                            ...                        \n",
       "93    got purely merit ' incredible kubbra sait int ...\n",
       "94             love shah rukh khan would love work arya\n",
       "95              ' part aditya participating bigg bos 15\n",
       "96      ' delhi crime ' changed everything shefali shah\n",
       "97    next 72 hour critical shoaib give update dad '...\n",
       "Name: title, Length: 98, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the title column to prep\n",
    "news_df['title'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in blogs using acquire.py\n",
    "codeup_df = acquire.acquire_codeup_blog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>blog_image</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>September 30, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>October 31, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>October 17, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      published_date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  September 30, 2018   \n",
       "1                                 Data Science Myths    October 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...    October 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair     August 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...     August 14, 2018   \n",
       "\n",
       "                                          blog_image  \\\n",
       "0  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "1  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "2  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the material\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rumor true time ha arrived codeup ha officiall...\n",
       "1    dimitri antoniou maggie giust data science big...\n",
       "2    dimitri antoniou week ago codeup launched imme...\n",
       "3    sa tech job fair third biannual san antonio te...\n",
       "4    competitor bootcamps closing model danger prog...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply all functions just created to the content column to prep\n",
    "codeup_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8. For each dataframe, make columns: title, original, clean, stemmed, lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ PREP ARTICLES ################################\n",
    "\n",
    "#take dataframe, specify the column, extra and exclude words\n",
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    #chain together clean, tokenize, remove stopwords\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    #chain clean, tokenize, stem, remove stopwords\n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    #clean clean, tokenize, lemmatize, remove stopwords\n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>reliance industries said statement 98 workers ...</td>\n",
       "      <td>relianc industri ha said statement 98 worker r...</td>\n",
       "      <td>reliance industry ha said statement 98 worker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>tesla ceo world ' secondrichest person elon mu...</td>\n",
       "      <td>tesla ceo world ' secondrichest person elon mu...</td>\n",
       "      <td>tesla ceo world ' secondrichest person elon mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>amazon monday denied speculations looking acce...</td>\n",
       "      <td>amazon monday deni specul wa look accept bitco...</td>\n",
       "      <td>amazon monday denied speculation wa looking ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>tesla ' billionaire ceo elon musk criticised a...</td>\n",
       "      <td>tesla ' billionair ceo elon musk criticis appl...</td>\n",
       "      <td>tesla ' billionaire ceo elon musk criticised a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>inox leisure denied report claimed amazon indi...</td>\n",
       "      <td>inox leisur deni report claim amazon india dis...</td>\n",
       "      <td>inox leisure denied report claimed amazon indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Among all my co-stars, I am closest to Tiger S...</td>\n",
       "      <td>Tara Sutaria, who made her Bollywood debut wit...</td>\n",
       "      <td>tara sutaria made bollywood debut tiger shroff...</td>\n",
       "      <td>tara sutaria made bollywood debut tiger shroff...</td>\n",
       "      <td>tara sutaria made bollywood debut tiger shroff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>I love every chapter of my life: Arjun on his ...</td>\n",
       "      <td>In his latest Instagram post, Arjun Kapoor sha...</td>\n",
       "      <td>latest instagram post arjun kapoor shared ' ' ...</td>\n",
       "      <td>hi latest instagram post arjun kapoor share ' ...</td>\n",
       "      <td>latest instagram post arjun kapoor shared ' ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I love Shah Rukh Khan, would love to work with...</td>\n",
       "      <td>Actor Arya, whose Tamil-language sports action...</td>\n",
       "      <td>actor arya whose tamillanguage sports action f...</td>\n",
       "      <td>actor arya whose tamillanguag sport action fil...</td>\n",
       "      <td>actor arya whose tamillanguage sport action fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>It was really bad: South actress Parul on expe...</td>\n",
       "      <td>South Indian actress Parul Yadav spoke about t...</td>\n",
       "      <td>south indian actress parul yadav spoke time go...</td>\n",
       "      <td>south indian actress parul yadav spoke time go...</td>\n",
       "      <td>south indian actress parul yadav spoke time go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Actor Umesh Kamat to sue media for linking him...</td>\n",
       "      <td>Marathi actor Umesh Kamat has issued a stateme...</td>\n",
       "      <td>marathi actor umesh kamat issued statement say...</td>\n",
       "      <td>marathi actor umesh kamat ha issu statement sa...</td>\n",
       "      <td>marathi actor umesh kamat ha issued statement ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Reliance Industries vaccinates 98% of workers,...   \n",
       "1   I will most likely not be on future earnings c...   \n",
       "2   Speculation around our plans for crypto not tr...   \n",
       "3   Musk criticises Apple's 'walled garden', cobal...   \n",
       "4   Factually incorrect: INOX on report of Amazon ...   \n",
       "..                                                ...   \n",
       "93  Among all my co-stars, I am closest to Tiger S...   \n",
       "94  I love every chapter of my life: Arjun on his ...   \n",
       "95  I love Shah Rukh Khan, would love to work with...   \n",
       "96  It was really bad: South actress Parul on expe...   \n",
       "97  Actor Umesh Kamat to sue media for linking him...   \n",
       "\n",
       "                                              content  \\\n",
       "0   Reliance Industries has said in a statement th...   \n",
       "1   Tesla CEO and the world's second-richest perso...   \n",
       "2   Amazon on Monday denied speculations that it w...   \n",
       "3   Tesla's billionaire CEO Elon Musk criticised A...   \n",
       "4   INOX Leisure denied a report that claimed Amaz...   \n",
       "..                                                ...   \n",
       "93  Tara Sutaria, who made her Bollywood debut wit...   \n",
       "94  In his latest Instagram post, Arjun Kapoor sha...   \n",
       "95  Actor Arya, whose Tamil-language sports action...   \n",
       "96  South Indian actress Parul Yadav spoke about t...   \n",
       "97  Marathi actor Umesh Kamat has issued a stateme...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   reliance industries said statement 98 workers ...   \n",
       "1   tesla ceo world ' secondrichest person elon mu...   \n",
       "2   amazon monday denied speculations looking acce...   \n",
       "3   tesla ' billionaire ceo elon musk criticised a...   \n",
       "4   inox leisure denied report claimed amazon indi...   \n",
       "..                                                ...   \n",
       "93  tara sutaria made bollywood debut tiger shroff...   \n",
       "94  latest instagram post arjun kapoor shared ' ' ...   \n",
       "95  actor arya whose tamillanguage sports action f...   \n",
       "96  south indian actress parul yadav spoke time go...   \n",
       "97  marathi actor umesh kamat issued statement say...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   relianc industri ha said statement 98 worker r...   \n",
       "1   tesla ceo world ' secondrichest person elon mu...   \n",
       "2   amazon monday deni specul wa look accept bitco...   \n",
       "3   tesla ' billionair ceo elon musk criticis appl...   \n",
       "4   inox leisur deni report claim amazon india dis...   \n",
       "..                                                ...   \n",
       "93  tara sutaria made bollywood debut tiger shroff...   \n",
       "94  hi latest instagram post arjun kapoor share ' ...   \n",
       "95  actor arya whose tamillanguag sport action fil...   \n",
       "96  south indian actress parul yadav spoke time go...   \n",
       "97  marathi actor umesh kamat ha issu statement sa...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   reliance industry ha said statement 98 worker ...  \n",
       "1   tesla ceo world ' secondrichest person elon mu...  \n",
       "2   amazon monday denied speculation wa looking ac...  \n",
       "3   tesla ' billionaire ceo elon musk criticised a...  \n",
       "4   inox leisure denied report claimed amazon indi...  \n",
       "..                                                ...  \n",
       "93  tara sutaria made bollywood debut tiger shroff...  \n",
       "94  latest instagram post arjun kapoor shared ' ' ...  \n",
       "95  actor arya whose tamillanguage sport action fi...  \n",
       "96  south indian actress parul yadav spoke time go...  \n",
       "97  marathi actor umesh kamat ha issued statement ...  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(news_df, 'content', extra_words =[], exclude_words=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9. Ask yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize- smaller dataset, it is slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming- larger dataset, it is faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
