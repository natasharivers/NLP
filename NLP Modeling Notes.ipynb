{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def clean(text: str) -> list:\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus we are using for modeling\n",
    "data = [\n",
    "    'Python is pretty cool',\n",
    "    'Python is a nice programming language with nice syntax',\n",
    "    'I think SQL is cool too',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can represent our data using:\n",
    "- Bag of words\n",
    "- n-grams\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "- document frequency\n",
    "- how often does word show up in document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**:\n",
    "\n",
    "\"Mary had a little lamb, little lamb, little lamb\"\n",
    "\n",
    "|a | had | lamb | little | Mary |\n",
    "|--|-----|------|--------|------|\n",
    "|1 | 1   | 3    | 3      | 1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bag_of_words = cv.fit_transform(data)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here bag_of_words is a sparse matrix. Usually you should keep it as such, but for demonstration we'll view the data within.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count vectorizer\n",
    "- turning documents into a vector of word counts\n",
    "\n",
    "<br>\n",
    "\n",
    "sparse matrix\n",
    "- more items with value 0, then items who are NOT 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the actual matrix \n",
    "bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>nice</th>\n",
       "      <th>pretty</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>syntax</th>\n",
       "      <th>think</th>\n",
       "      <th>too</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool  is  language  nice  pretty  programming  python  sql  syntax  think  \\\n",
       "0     1   1         0     0       1            0       1    0       0      0   \n",
       "1     0   1         1     2       0            1       1    0       1      0   \n",
       "2     1   1         0     0       0            0       0    1       0      1   \n",
       "\n",
       "   too  with  \n",
       "0    0     0  \n",
       "1    0     1  \n",
       "2    1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn this word bag matrix into a DF\n",
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency\n",
    "- 1 / (how many documents the word appears in)\n",
    "- a measure that helps identify how important a word is in a document\n",
    "- combination of how often a word appears in a document (tf) and how unqiue the word is among documents (idf)\n",
    "- used by search engines\n",
    "- naturally helps filter out stopwords\n",
    "- tf is for a single document, idf is for a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "**TF**:\n",
    "- term frequency: how often it appears\n",
    "\n",
    "<br>\n",
    "\n",
    "**IDF**:\n",
    "- helps uniquely identify a document.\n",
    "    - if its only in one document, it might be unique\n",
    "\n",
    "**Examples**:\n",
    "- doesn't show up frequently = low tf-idf\n",
    "- shows up a lot in a single document= high tf AND high idf\n",
    "- \"is\" from wordbag.. shows up in all 3 documents = high tf, low idf\n",
    "\n",
    "<br>\n",
    "\n",
    "- tf-idf(word, doc, D) = tf(word, doc) Ã— idf(word, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>nice</th>\n",
       "      <th>pretty</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>syntax</th>\n",
       "      <th>think</th>\n",
       "      <th>too</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197673</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.669378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.254540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cool        is  language      nice    pretty  programming    python  \\\n",
       "0  0.480458  0.373119  0.000000  0.000000  0.631745     0.000000  0.480458   \n",
       "1  0.000000  0.197673  0.334689  0.669378  0.000000     0.334689  0.254540   \n",
       "2  0.383770  0.298032  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "\n",
       "        sql    syntax     think       too      with  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.334689  0.000000  0.000000  0.334689  \n",
       "2  0.504611  0.000000  0.504611  0.504611  0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(data)\n",
    "\n",
    "pprint(data)\n",
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Ngrams\n",
    "- sets/groups of words\n",
    "- bigrams, trigrams, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show range of words between 2 and 2 (just bigrams)\n",
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bag_of_words = cv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool too</th>\n",
       "      <th>is cool</th>\n",
       "      <th>is nice</th>\n",
       "      <th>is pretty</th>\n",
       "      <th>language with</th>\n",
       "      <th>nice programming</th>\n",
       "      <th>nice syntax</th>\n",
       "      <th>pretty cool</th>\n",
       "      <th>programming language</th>\n",
       "      <th>python is</th>\n",
       "      <th>sql is</th>\n",
       "      <th>think sql</th>\n",
       "      <th>with nice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool too  is cool  is nice  is pretty  language with  nice programming  \\\n",
       "0         0        0        0          1              0                 0   \n",
       "1         0        0        1          0              1                 1   \n",
       "2         1        1        0          0              0                 0   \n",
       "\n",
       "   nice syntax  pretty cool  programming language  python is  sql is  \\\n",
       "0            0            1                     0          1       0   \n",
       "1            1            0                     1          1       0   \n",
       "2            0            0                     0          0       1   \n",
       "\n",
       "   think sql  with nice  \n",
       "0          0          0  \n",
       "1          0          1  \n",
       "2          1          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DF of bigrams per sentence\n",
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#read in spam/ham dataset\n",
    "df = pd.read_csv('spam_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306708548350908"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#term frequency\n",
    "cv = CountVectorizer()\n",
    "#apply cleaning function to text, then join everything back together\n",
    "X = cv.fit_transform(df.text.apply(clean).apply(' '.join))\n",
    "#label (ham or spam)\n",
    "y = df.label\n",
    "\n",
    "#train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)\n",
    "\n",
    "#create model - decision tree classifier\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "#fit\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#accuracy score <-- 93%\n",
    "tree.score(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306708548350908"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to predict accuracy\n",
    "#the number of times that X_train is equal to y_train\n",
    "(tree.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9147982062780269"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score of test split <-- 91%\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Results\n",
    "A super-useful feature of decision trees and linear models is that they do some built-in feature selection through the coefficeints or feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see which features matter most\n",
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8791,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique words in the entire corpus\n",
    "tree.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ela            0.000000\n",
       "embarassed     0.000000\n",
       "elaborate      0.000000\n",
       "elaborating    0.000000\n",
       "embarassing    0.000000\n",
       "didnt          0.003178\n",
       "asa            0.003320\n",
       "evening        0.005961\n",
       "co             0.006182\n",
       "youre          0.010495\n",
       "stop           0.011767\n",
       "ill            0.013857\n",
       "service        0.020439\n",
       "mobile         0.026495\n",
       "reply          0.042182\n",
       "later          0.059484\n",
       "claim          0.073024\n",
       "text           0.086027\n",
       "txt            0.280117\n",
       "call           0.357470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#panda Series where index is unique words and value is IDF\n",
    "pd.Series(dict(zip(cv.get_feature_names(), tree.feature_importances_))).sort_values().tail(20)\n",
    "\n",
    "#seeing the word 'call' seems to be very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "- try other model types\n",
    "- use same model with different representations (ngrams vs TF-IDF)\n",
    "- look at accuracy, recall, precision\n",
    "- Look at other metrics, is accuracy the best choice here?\n",
    "- Try ngrams instead of single words\n",
    "- Try a combination of ngrams and words (ngram_range=(1, 2) for words and bigrams)\n",
    "- Try using tf-idf instead of bag of words\n",
    "- Combine the top n performing words with the other features that you have engineered (the CountVectorizer and TfidfVectorizer have a vocabulary argument you can use to restrict the words used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "After going through modeling...\n",
    "- go back and change lemmatizing to stemming,\n",
    "- does it change the results of model accuracy?\n",
    "- if theres only a small increase in performance, go with stemming (for performance)\n",
    "- you can do either (no wrong way to clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- can use KNN, Random Forest, Decision Tree\n",
    "- recall, percision, accuracy... which is most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
